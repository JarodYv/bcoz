# 因果AI如何发现因果

## 什么是因果发现

先看一个简单的例子。假设我们有一个数据集，这个数据集包含如下变量：冰激凌销量、鲨鱼袭击次数、温度和风速。

我们假设下列陈述都为真。夏季炎热的气候使得人们购买冰激凌和游泳潜水的次数增加，从而导致鲨鱼袭击事件增多。其他气象现象--比如风--驱使鲨鱼在近海岸活动也会增加鲨鱼袭击。

这些都是因果关系和因果效用。我们可以将其总结为一张因果图（如图1）。因果发现的目的是从数据中找到正确的因果结构，就像下图一样：

![](_media\how_can_ai_discover_cause_and_effect_p1.png)

<center>图1</center>

## 因果知识如何获取

因果知识可以通过3中互补的方法获得：

* 干预实验
* 人类经验和直觉
* 因果发现算法

实验是发现因果关系的黄金准则，但很多场景下干预实验是不道德的或无法操作的。比如我们无法将人们置于被鲨鱼攻击的危险中，我们也无法人为改变天气去观测对冰淇凌销量的影响。

我们先聚焦在因果发现算法上，后面再回过头来讨论这3种方法。

## 关联非因果

从观测数据中发现因果关系很难，因为相关不意味着因果。

例如，鲨鱼袭击和冰淇凌销量有相关性或者说他们在统计上彼此相关（如图2）。但二者之间没有直接的因果关系--是因为维度这个共因导致二者呈现出相关性。这里温度被称为混淆因子。

![img](C:\Users\plan\GitHub\bcoz\docs\_media\Screenshot-2021-12-15-at-14.18.50-1024x481.webp)

<center>图2 关联不蕴含因果</center>

如果因果能直接从关联中获取，那么因果发现就变得很容易了，现在的机器学习算法应该早就解决了这个问题。但是正如上面所说的那样，因果发现需要特别的技术去发掘隐藏在关联背后的数据产生过程。

![](_media\how_can_ai_discover_cause_and_effect_p3.png)

<center>图3 因果关系产生数据中的相关性。因果AI能够发现这些潜在的因果关系，而机器学习只是分析相关性。</center>

## 从数据中找寻因果证据

因果发现算法可以从数据中找到因果关系的线索。其中 **条件独立** 是众多算法找寻的关键证据。下面我们详细拆解一下这个概念。

如果两个变量之间没有任何关系，则说这两个变量独立。独立意味着一个变量的值不会告诉我们关于另一个变量的任何信息。比如特斯拉的股价跟鲨鱼袭击相互独立。

条件独立建立在这面这个概念之上：

> 当给定变量C的值时X和Y彼此独立，那么变量X，Y对给定的变量（或一组变量）C条件独立。

当给定温度后，鲨鱼袭击和冰激凌销量条件独立。因为如果我们已知气温，鲨鱼袭击的发生率不会对冰淇淋销量提供任何新的信息。

为什么条件独立能帮助因果发现？

直觉上，条件独立检验有点类似控制实验。在实验中，我们试图通过控制环境来隔离因果效用，然后调节我们感兴趣的变量。因果发现软件无法做到跟控制实验一样控制环境，但在所有背景因素上进行调节是次优的选择。

## 经典因果发现算法

接下来让我们宏观地看一下因果发现算法，去了解因果发现是如何工作的。

“基于约束”的算法是因果发现算法的一类，它采用条件独立关系作为约束，然后构建能够表示这些约束的因果结构。

![](_media\how_can_ai_discover_cause_and_effect_p4.png)

<center>图4 基于约束的因果发现算法的流程。首先从数据中建立条件独立关系，然后因果发现算法发现能够表示这些条件独立约束的因果模型。算法最终输出一系列与数据匹配的候选因果结构，称之为“马尔可夫等价类”。</center>

其中"PC算法"是一个经典的基于约束的因果发现算法，

<div>
    <div style="width:300px;height:100%;display:inline-block;">
        <img src="_media\how_can_ai_discover_cause_and_effect_p5.png"
    </div>
    <div style="position: absolute; left:320px; height:100%;display:inline-block;">
        <p style="margin-top: 20px;">
            第一步：假设所有变量之间都存在某种关联，我们不知道关联的方向；
        </p>
        <p style="margin-top: 150px;">
            第二步：进行一系列条件独立检验，找到独立变量，去掉相关的边。然后寻找一个变量对另一个变量的条件独立性，移除边的箭头。重复上述步骤，逐步增加参与条件独立检验的变量。
        </p>
        <p style="margin-top: 150px;">
            第三步：定向“对撞结构”（形如X1 → Y ← X2的因果结构）。对撞结构在数据中具有独特的特征，因此可以利用它们来确定边的方向。
        </p>
    </div>
</div>

<center>图5 PC算法分解</center>

## 应用因果发现的挑战

因果发现算法（例如PC算法）是人工智能在概念上超越传统机器学习的巨大飞跃。但不幸的是，传统算法在实际应用中存在局限性。

### 假设过强

许多流行的因果发现算法在大多数用例中都会做出过强的假设。例如，PC算法假设数据之外没有混杂因子，这通常是错误的，可能会带来不准确的因果模型。

![](_media\how_can_ai_discover_cause_and_effect_p6.png)

<center>图6 某些标准算法假设不存在未观测的混杂因子。但现实中往往存在未观测的混杂因子。例如季节（数据中没有）是温度和风速的共因。</center>

### 计算量大

因果发现算法需要大量计算。例如，随着数据越来越大，PC需要运行的条件独立检验数量会急剧增大。经典的“基于分数”算法是另一种直接搜索可能的因果结构空间的核心方法，但也存在效率低下的问题。这使得大多数因果发现算法在解决实际问题时都显得太慢了。

### 模型漂移

我们研究发现，因果发现算法不能保证有稳定的模型输出。例如我们发现在基于分数的算法上，修改数据的单位会带来完全不同的因果模型输出。这显然不合理，因果模型不应该因为温度数据是用摄氏度表示还是华氏度表示而不同。

### 选择困难

对于任何给定的应用，都有大量的因果发现算法可供选择。有些算法比其他算法更适合某些用例。如何选择正确的算法需要大量专业知识和经验。

## 如何更进一步

## 因果发现的好处